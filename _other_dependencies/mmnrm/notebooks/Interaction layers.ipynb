{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils import set_random_seed\n",
    "set_random_seed()\n",
    "    \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from layers.interaction import ExactInteractions\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact layer \n",
    "\n",
    "Creates a interaction matrix S were each entry $i$ and $j$ are defined by:\n",
    "\n",
    "$s_{ij}=\\begin{cases}1 & q_i = d_i\\\\0 & otherwise\\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exact_interactions (ExactIntera (None, 10, 12)       0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((10,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((12,), dtype=\"int32\")\n",
    "\n",
    "exact_interaction = ExactInteractions()\n",
    "\n",
    "_out = exact_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,4,(1, 10))\n",
    "document = np.random.randint(1,4,(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,5:] = np.zeros(5,)\n",
    "document[:,6:] = np.zeros(6,)\n",
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Layer with term importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exact_interactions (ExactIntera (None, 8, 4, 3)      0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "input_query_t_importance = tf.keras.layers.Input((8,), dtype=\"float32\")\n",
    "input_sentence_t_importance = tf.keras.layers.Input((4,), dtype=\"float32\")\n",
    "\n",
    "_inputs = [input_query, input_sentence, input_query_t_importance, input_sentence_t_importance]\n",
    "\n",
    "exact_interaction = ExactInteractions()\n",
    "\n",
    "_out = exact_interaction(_inputs)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=_inputs, outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,10,(1, 8))\n",
    "sentence = np.random.randint(1,10,(1, 4))\n",
    "\n",
    "query_importance = np.random.random((1, 8))\n",
    "sentence_importance = np.random.random((1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "[[0.45049927 0.45049927 0.45049927 0.45049927]\n",
      " [0.01326496 0.01326496 0.01326496 0.01326496]\n",
      " [0.94220173 0.94220173 0.94220173 0.94220173]\n",
      " [0.5632882  0.5632882  0.5632882  0.5632882 ]\n",
      " [0.3854165  0.3854165  0.3854165  0.3854165 ]\n",
      " [0.01596625 0.01596625 0.01596625 0.01596625]\n",
      " [0.23089382 0.23089382 0.23089382 0.23089382]\n",
      " [0.24102546 0.24102546 0.24102546 0.24102546]]\n",
      "[[0.68326354 0.6099967  0.8331949  0.17336465]\n",
      " [0.68326354 0.6099967  0.8331949  0.17336465]\n",
      " [0.68326354 0.6099967  0.8331949  0.17336465]\n",
      " [0.68326354 0.6099967  0.8331949  0.17336465]\n",
      " [0.68326354 0.6099967  0.8331949  0.17336465]\n",
      " [0.68326354 0.6099967  0.8331949  0.17336465]\n",
      " [0.68326354 0.6099967  0.8331949  0.17336465]\n",
      " [0.68326354 0.6099967  0.8331949  0.17336465]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([query, sentence, query_importance, sentence_importance])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0.45049927 0.45049927 0.         0.        ]\n",
      " [0.01326496 0.01326496 0.         0.        ]\n",
      " [0.94220173 0.94220173 0.         0.        ]\n",
      " [0.5632882  0.5632882  0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "[[0.68326354 0.6099967  0.         0.        ]\n",
      " [0.68326354 0.6099967  0.         0.        ]\n",
      " [0.68326354 0.6099967  0.         0.        ]\n",
      " [0.68326354 0.6099967  0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "query[:,4:] = np.zeros(4,)\n",
    "sentence[:,2:] = np.zeros(2,)\n",
    "query_importance[:,4:] = np.zeros(4,)\n",
    "sentence_importance[:,2:] = np.zeros(2,)\n",
    "\n",
    "y = model.predict([query, sentence, query_importance, sentence_importance])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'interactions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8c111a41b320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minteractions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSemanticInteractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'interactions'"
     ]
    }
   ],
   "source": [
    "from interactions import SemanticInteractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG created tokenizer disk4_5_RegexTokenizer\n",
      "False False\n",
      "[LOAD FROM CACHE] Load embedding matrix from /backup/IR/embedding_wiki_disk4_5_RegexTokenizer\n"
     ]
    }
   ],
   "source": [
    "from nir.embeddings import FastText\n",
    "from nir.tokenizers import Regex\n",
    "\n",
    "cache_folder = \"/backup/IR\"\n",
    "prefix_name = \"disk4_5\"\n",
    "\n",
    "# load tokenizer\n",
    "tk = Regex.load_from_json(cache_folder=cache_folder, prefix_name=prefix_name)\n",
    "\n",
    "# load embedding matrix\n",
    "ft = FastText.maybe_load(cache_folder = cache_folder,\n",
    "                         prefix_name = prefix_name,\n",
    "                         path = \"/backup/pre-trained_embeddings/fasttext/wiki.en.bin\",\n",
    "                         tokenizer = tk)\n",
    "\n",
    "emb_matrix = ft.embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EMBEDDING MATRIX SHAPE] (228107, 300)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "semantic_interactions (Semantic (None, 8, 4, 3)      600         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "semantic_interaction = SemanticInteractions(emb_matrix)\n",
    "\n",
    "_out = semantic_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,100000,(1, 8))\n",
    "document = np.random.randint(1,100000,(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02600097  0.1523608   0.05045402  0.02214804]\n",
      " [-0.08191848  0.22749323  0.07356641  0.13409927]\n",
      " [ 0.16650498  0.00378791  0.17630842  0.17259032]\n",
      " [-0.02516811  0.07732472  0.17895198  0.17647892]\n",
      " [-0.02122113  0.21902236  0.1314221   0.10899112]\n",
      " [-0.17898647  0.2909802   0.2858552   0.18254572]\n",
      " [ 0.06219951  0.04914713  0.06359807  0.0281321 ]\n",
      " [ 0.03048387  0.15481643  0.07244178  0.12701723]]\n",
      "[[ 0.07625329  0.07625329  0.07625329  0.07625329]\n",
      " [ 0.06301482  0.06301482  0.06301482  0.06301482]\n",
      " [ 0.1634911   0.1634911   0.1634911   0.1634911 ]\n",
      " [-0.01706506 -0.01706506 -0.01706506 -0.01706506]\n",
      " [ 0.10522851  0.10522851  0.10522851  0.10522851]\n",
      " [-0.13724078 -0.13724078 -0.13724078 -0.13724078]\n",
      " [ 0.08696583  0.08696583  0.08696583  0.08696583]\n",
      " [ 0.07390243  0.07390243  0.07390243  0.07390243]]\n",
      "[[-0.09235676  0.03288544 -0.07960127  0.06511894]\n",
      " [-0.09235676  0.03288544 -0.07960127  0.06511894]\n",
      " [-0.09235676  0.03288544 -0.07960127  0.06511894]\n",
      " [-0.09235676  0.03288544 -0.07960127  0.06511894]\n",
      " [-0.09235676  0.03288544 -0.07960127  0.06511894]\n",
      " [-0.09235676  0.03288544 -0.07960127  0.06511894]\n",
      " [-0.09235676  0.03288544 -0.07960127  0.06511894]\n",
      " [-0.09235676  0.03288544 -0.07960127  0.06511894]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02600097  0.1523608  -0.         -0.        ]\n",
      " [-0.08191848  0.22749323 -0.         -0.        ]\n",
      " [ 0.16650498  0.00378791  0.          0.        ]\n",
      " [-0.02516811  0.07732472 -0.         -0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]]\n",
      "[[ 0.07625329  0.07625329  0.          0.        ]\n",
      " [ 0.06301482  0.06301482  0.          0.        ]\n",
      " [ 0.1634911   0.1634911   0.          0.        ]\n",
      " [-0.01706506 -0.01706506 -0.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.        ]]\n",
      "[[-0.09235676  0.03288544  0.          0.        ]\n",
      " [-0.09235676  0.03288544  0.          0.        ]\n",
      " [-0.09235676  0.03288544  0.          0.        ]\n",
      " [-0.09235676  0.03288544  0.          0.        ]\n",
      " [-0.          0.          0.          0.        ]\n",
      " [-0.          0.          0.          0.        ]\n",
      " [-0.          0.          0.          0.        ]\n",
      " [-0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,4:] = np.zeros(4,)\n",
    "document[:,2:] = np.zeros(2,)\n",
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context semantic layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_wrapper import load_bert_model\n",
    "from interactions import ContextedSemanticInteractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ALBERT model: albert_base version: 2\n",
      "Already  fetched:  albert_base.tar.gz\n",
      "already unpacked at: .models/albert_base\n",
      "WARNING:tensorflow:From /home/tiagoalmeida/Spatial-RNN-GRU/tf2/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Done loading 22 BERT weights from: .models/albert_base into <bert.model.BertModelLayer object at 0x7f7b95f19f60> (prefix:albert_base). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from saved model: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 41)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "contexted_semantic_interactions (None, 20, 41, 3)    11094272    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,094,272\n",
      "Trainable params: 1,536\n",
      "Non-trainable params: 11,092,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((20,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((41,), dtype=\"int32\")\n",
    "\n",
    "bert_model = load_bert_model(\"albert_base\", 64)\n",
    "\n",
    "semantic_interaction = ContextedSemanticInteractions(context_embedding_layer = bert_model,\n",
    "                                                     learn_term_weights = True,\n",
    "                                                     cls_token_id = 2,\n",
    "                                                     sep_token_id = 3,\n",
    "                                                     pad_token_id = 0)\n",
    "\n",
    "_out = semantic_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2Wnir",
   "language": "python",
   "name": "tensor2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
